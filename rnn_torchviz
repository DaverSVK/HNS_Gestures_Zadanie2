digraph {
	graph [size="36.449999999999996,36.449999999999996"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140321311688416 [label="
 (1, 5)" fillcolor=darkolivegreen1]
	140321482353264 [label=AddmmBackward0]
	140321482511968 -> 140321482353264
	140321500549024 [label="classifier.10.bias
 (5)" fillcolor=lightblue]
	140321500549024 -> 140321482511968
	140321482511968 [label=AccumulateGrad]
	140321482512640 -> 140321482353264
	140321482512640 [label=LeakyReluBackward1]
	140321482446816 -> 140321482512640
	140321482446816 [label=AddmmBackward0]
	140321482366864 -> 140321482446816
	140321500549184 [label="classifier.8.bias
 (64)" fillcolor=lightblue]
	140321500549184 -> 140321482366864
	140321482366864 [label=AccumulateGrad]
	140321482368304 -> 140321482446816
	140321482368304 [label=LeakyReluBackward1]
	140321482471696 -> 140321482368304
	140321482471696 [label=AddmmBackward0]
	140321482460080 -> 140321482471696
	140321500549744 [label="classifier.6.bias
 (128)" fillcolor=lightblue]
	140321500549744 -> 140321482460080
	140321482460080 [label=AccumulateGrad]
	140321482472656 -> 140321482471696
	140321482472656 [label=LeakyReluBackward1]
	140321482471120 -> 140321482472656
	140321482471120 [label=AddmmBackward0]
	140321482471408 -> 140321482471120
	140321500549584 [label="classifier.4.bias
 (256)" fillcolor=lightblue]
	140321500549584 -> 140321482471408
	140321482471408 [label=AccumulateGrad]
	140321482601232 -> 140321482471120
	140321482601232 [label=LeakyReluBackward1]
	140321482588704 -> 140321482601232
	140321482588704 [label=AddmmBackward0]
	140321482593264 -> 140321482588704
	140321500549424 [label="classifier.2.bias
 (512)" fillcolor=lightblue]
	140321500549424 -> 140321482593264
	140321482593264 [label=AccumulateGrad]
	140321482593168 -> 140321482588704
	140321482593168 [label=LeakyReluBackward1]
	140321482591104 -> 140321482593168
	140321482591104 [label=AddmmBackward0]
	140321482590000 -> 140321482591104
	140321500549984 [label="classifier.0.bias
 (1024)" fillcolor=lightblue]
	140321500549984 -> 140321482590000
	140321482590000 [label=AccumulateGrad]
	140321482588752 -> 140321482591104
	140321482588752 [label=ViewBackward0]
	140321482589184 -> 140321482588752
	140321482589184 [label=MaxPool2DWithIndicesBackward0]
	140321482599504 -> 140321482589184
	140321482599504 [label=ConvolutionBackward0]
	140321482593456 -> 140321482599504
	140321482593456 [label=AddBackward0]
	140321482589424 -> 140321482593456
	140321482589424 [label=LeakyReluBackward1]
	140321482593408 -> 140321482589424
	140321482593408 [label=CudnnBatchNormBackward0]
	140321482600464 -> 140321482593408
	140321482600464 [label=ConvolutionBackward0]
	140321482589280 -> 140321482600464
	140321482589280 [label=MaxPool2DWithIndicesBackward0]
	140321482590720 -> 140321482589280
	140321482590720 [label=ConvolutionBackward0]
	140321482589616 -> 140321482590720
	140321482589616 [label=AddBackward0]
	140321482604016 -> 140321482589616
	140321482604016 [label=LeakyReluBackward1]
	140321482603440 -> 140321482604016
	140321482603440 [label=CudnnBatchNormBackward0]
	140321482588896 -> 140321482603440
	140321482588896 [label=ConvolutionBackward0]
	140321482593216 -> 140321482588896
	140321482593216 [label=MaxPool2DWithIndicesBackward0]
	140321482589856 -> 140321482593216
	140321482589856 [label=ConvolutionBackward0]
	140321482602720 -> 140321482589856
	140321482602720 [label=AddBackward0]
	140321482591584 -> 140321482602720
	140321482591584 [label=LeakyReluBackward1]
	140321482589520 -> 140321482591584
	140321482589520 [label=CudnnBatchNormBackward0]
	140321482592064 -> 140321482589520
	140321482592064 [label=ConvolutionBackward0]
	140321482594176 -> 140321482592064
	140321482594176 [label=MaxPool2DWithIndicesBackward0]
	140321482599888 -> 140321482594176
	140321482599888 [label=ConvolutionBackward0]
	140321482592592 -> 140321482599888
	140321482592592 [label=AddBackward0]
	140321482591872 -> 140321482592592
	140321482591872 [label=LeakyReluBackward1]
	140321482593024 -> 140321482591872
	140321482593024 [label=CudnnBatchNormBackward0]
	140321482591824 -> 140321482593024
	140321482591824 [label=ConvolutionBackward0]
	140321482592496 -> 140321482591824
	140321482592496 [label=ConvolutionBackward0]
	140321482592640 -> 140321482592496
	140321500557184 [label="conv0.weight
 (64, 1, 3, 3)" fillcolor=lightblue]
	140321500557184 -> 140321482592640
	140321482592640 [label=AccumulateGrad]
	140321482592832 -> 140321482592496
	140321500555424 [label="conv0.bias
 (64)" fillcolor=lightblue]
	140321500555424 -> 140321482592832
	140321482592832 [label=AccumulateGrad]
	140321482589376 -> 140321482591824
	140321500555664 [label="preserve.0.0.weight
 (64, 64, 5, 5)" fillcolor=lightblue]
	140321500555664 -> 140321482589376
	140321482589376 [label=AccumulateGrad]
	140321482589472 -> 140321482591824
	140321500555584 [label="preserve.0.0.bias
 (64)" fillcolor=lightblue]
	140321500555584 -> 140321482589472
	140321482589472 [label=AccumulateGrad]
	140321482601040 -> 140321482593024
	140321500557024 [label="preserve.0.1.weight
 (64)" fillcolor=lightblue]
	140321500557024 -> 140321482601040
	140321482601040 [label=AccumulateGrad]
	140321482594128 -> 140321482593024
	140321500555984 [label="preserve.0.1.bias
 (64)" fillcolor=lightblue]
	140321500555984 -> 140321482594128
	140321482594128 [label=AccumulateGrad]
	140321482592496 -> 140321482592592
	140321482601184 -> 140321482599888
	140321500555024 [label="collapse.0.0.weight
 (64, 64, 5, 5)" fillcolor=lightblue]
	140321500555024 -> 140321482601184
	140321482601184 [label=AccumulateGrad]
	140321482590912 -> 140321482599888
	140321500555104 [label="collapse.0.0.bias
 (64)" fillcolor=lightblue]
	140321500555104 -> 140321482590912
	140321482590912 [label=AccumulateGrad]
	140321482591680 -> 140321482592064
	140321500555824 [label="preserve.1.0.weight
 (64, 64, 5, 5)" fillcolor=lightblue]
	140321500555824 -> 140321482591680
	140321482591680 [label=AccumulateGrad]
	140321482592352 -> 140321482592064
	140321500554704 [label="preserve.1.0.bias
 (64)" fillcolor=lightblue]
	140321500554704 -> 140321482592352
	140321482592352 [label=AccumulateGrad]
	140321482591536 -> 140321482589520
	140321500555184 [label="preserve.1.1.weight
 (64)" fillcolor=lightblue]
	140321500555184 -> 140321482591536
	140321482591536 [label=AccumulateGrad]
	140321482591632 -> 140321482589520
	140321500553904 [label="preserve.1.1.bias
 (64)" fillcolor=lightblue]
	140321500553904 -> 140321482591632
	140321482591632 [label=AccumulateGrad]
	140321482594176 -> 140321482602720
	140321482603104 -> 140321482589856
	140321500553024 [label="collapse.1.0.weight
 (64, 64, 5, 5)" fillcolor=lightblue]
	140321500553024 -> 140321482603104
	140321482603104 [label=AccumulateGrad]
	140321482600272 -> 140321482589856
	140321500553104 [label="collapse.1.0.bias
 (64)" fillcolor=lightblue]
	140321500553104 -> 140321482600272
	140321482600272 [label=AccumulateGrad]
	140321482604496 -> 140321482588896
	140321500553424 [label="preserve.2.0.weight
 (64, 64, 5, 5)" fillcolor=lightblue]
	140321500553424 -> 140321482604496
	140321482604496 [label=AccumulateGrad]
	140321482593312 -> 140321482588896
	140321500553504 [label="preserve.2.0.bias
 (64)" fillcolor=lightblue]
	140321500553504 -> 140321482593312
	140321482593312 [label=AccumulateGrad]
	140321482593984 -> 140321482603440
	140321500552384 [label="preserve.2.1.weight
 (64)" fillcolor=lightblue]
	140321500552384 -> 140321482593984
	140321482593984 [label=AccumulateGrad]
	140321482603824 -> 140321482603440
	140321500552464 [label="preserve.2.1.bias
 (64)" fillcolor=lightblue]
	140321500552464 -> 140321482603824
	140321482603824 [label=AccumulateGrad]
	140321482593216 -> 140321482589616
	140321482592208 -> 140321482590720
	140321500552704 [label="collapse.2.0.weight
 (64, 64, 5, 5)" fillcolor=lightblue]
	140321500552704 -> 140321482592208
	140321482592208 [label=AccumulateGrad]
	140321482594320 -> 140321482590720
	140321500551584 [label="collapse.2.0.bias
 (64)" fillcolor=lightblue]
	140321500551584 -> 140321482594320
	140321482594320 [label=AccumulateGrad]
	140321482590240 -> 140321482600464
	140321500551664 [label="preserve.3.0.weight
 (64, 64, 5, 5)" fillcolor=lightblue]
	140321500551664 -> 140321482590240
	140321482590240 [label=AccumulateGrad]
	140321482590144 -> 140321482600464
	140321500550384 [label="preserve.3.0.bias
 (64)" fillcolor=lightblue]
	140321500550384 -> 140321482590144
	140321482590144 [label=AccumulateGrad]
	140321482590528 -> 140321482593408
	140321500550464 [label="preserve.3.1.weight
 (64)" fillcolor=lightblue]
	140321500550464 -> 140321482590528
	140321482590528 [label=AccumulateGrad]
	140321482589808 -> 140321482593408
	140321500550544 [label="preserve.3.1.bias
 (64)" fillcolor=lightblue]
	140321500550544 -> 140321482589808
	140321482589808 [label=AccumulateGrad]
	140321482589280 -> 140321482593456
	140321482592928 -> 140321482599504
	140321500551824 [label="collapse.3.0.weight
 (64, 64, 5, 5)" fillcolor=lightblue]
	140321500551824 -> 140321482592928
	140321482592928 [label=AccumulateGrad]
	140321482588800 -> 140321482599504
	140321500551904 [label="collapse.3.0.bias
 (64)" fillcolor=lightblue]
	140321500551904 -> 140321482588800
	140321482588800 [label=AccumulateGrad]
	140321482589904 -> 140321482591104
	140321482589904 [label=TBackward0]
	140321482588656 -> 140321482589904
	140321500550064 [label="classifier.0.weight
 (1024, 1600)" fillcolor=lightblue]
	140321500550064 -> 140321482588656
	140321482588656 [label=AccumulateGrad]
	140321482590672 -> 140321482588704
	140321482590672 [label=TBackward0]
	140321482397424 -> 140321482590672
	140321500550144 [label="classifier.2.weight
 (512, 1024)" fillcolor=lightblue]
	140321500550144 -> 140321482397424
	140321482397424 [label=AccumulateGrad]
	140321482591008 -> 140321482471120
	140321482591008 [label=TBackward0]
	140321482591200 -> 140321482591008
	140321500556304 [label="classifier.4.weight
 (256, 512)" fillcolor=lightblue]
	140321500556304 -> 140321482591200
	140321482591200 [label=AccumulateGrad]
	140321482457488 -> 140321482471696
	140321482457488 [label=TBackward0]
	140321482468720 -> 140321482457488
	140321500549664 [label="classifier.6.weight
 (128, 256)" fillcolor=lightblue]
	140321500549664 -> 140321482468720
	140321482468720 [label=AccumulateGrad]
	140321482365808 -> 140321482446816
	140321482365808 [label=TBackward0]
	140321482462432 -> 140321482365808
	140321500549344 [label="classifier.8.weight
 (64, 128)" fillcolor=lightblue]
	140321500549344 -> 140321482462432
	140321482462432 [label=AccumulateGrad]
	140321482370560 -> 140321482353264
	140321482370560 [label=TBackward0]
	140321482469104 -> 140321482370560
	140321500549264 [label="classifier.10.weight
 (5, 64)" fillcolor=lightblue]
	140321500549264 -> 140321482469104
	140321482469104 [label=AccumulateGrad]
	140321482353264 -> 140321311688416
}
